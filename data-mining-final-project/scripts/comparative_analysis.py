"""
TUGAS BESAR PENAMBANGAN DATA - COMPARATIVE ANALYSIS
====================================================
Analisis Komparatif: Dataset 1 vs Dataset 2
Tujuan: Menentukan pada dataset mana metode preprocessing bekerja lebih efektif

This script runs after both dataset1_analysis.py and dataset2_analysis.py
"""

import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np

print("="*80)
print("üìä COMPARATIVE ANALYSIS: Dataset 1 vs Dataset 2")
print("="*80)

project_root = Path(__file__).parent.parent

# Load results
try:
    df1 = pd.read_csv(project_root / 'outputs' / 'dataset1-output' / 'comparison_summary.csv')
    df2 = pd.read_csv(project_root / 'outputs' / 'dataset2-output' / 'comparison_summary.csv')
except FileNotFoundError:
    print("\n‚ùå Error: Run dataset1_analysis.py and dataset2_analysis.py first!")
    exit(1)

print("\n[1/3] Loading results...")
print(f"‚úÖ Dataset 1 results loaded")
print(f"‚úÖ Dataset 2 results loaded")

# Extract key metrics
print("\n[2/3] Comparative Analysis...")
print("="*80)
print("\nDATASET 1 (Pharmacy - Time Series Data):")
print("-"*80)
for _, row in df1.iterrows():
    print(f"{row['Method']:<25} | R¬≤: {row['R2_Test']:.4f} | RMSE: {row['RMSE_Test']:.4f} | Improvement: {row['RMSE_Improvement_%']:+.2f}%")

print("\nDATASET 2 (Wave - Physical Sensor Data):")
print("-"*80)
for _, row in df2.iterrows():
    print(f"{row['Method']:<25} | R¬≤: {row['R2_Test']:.4f} | RMSE: {row['RMSE_Test']:.4f} | Improvement: {row['RMSE_Improvement_%']:+.2f}%")

# Comparative insights
print("\n"+"="*80)
print("CRITICAL THINKING & INSIGHTS")
print("="*80)

# Dataset 1 analysis
d1_baseline = df1[df1['Method'] == 'Baseline (All Features)'].iloc[0]
d1_rfecv = df1[df1['Method'] == 'RFECV'].iloc[0]
d1_kbest = df1[df1['Method'] == 'SelectKBest'].iloc[0]

# Dataset 2 analysis
d2_baseline = df2[df2['Method'] == 'Baseline (All Features)'].iloc[0]
d2_rfecv = df2[df2['Method'] == 'RFECV'].iloc[0]
d2_kbest = df2[df2['Method'] == 'SelectKBest'].iloc[0]

# Determine effectiveness
d1_effective = (d1_rfecv['RMSE_Test'] < d1_baseline['RMSE_Test'] or 
                d1_kbest['RMSE_Test'] < d1_baseline['RMSE_Test'])
d2_effective = (d2_rfecv['RMSE_Test'] < d2_baseline['RMSE_Test'] or 
                d2_kbest['RMSE_Test'] < d2_baseline['RMSE_Test'])

d1_improvement = max(d1_rfecv['RMSE_Improvement_%'], d1_kbest['RMSE_Improvement_%'])
d2_improvement = max(d2_rfecv['RMSE_Improvement_%'], d2_kbest['RMSE_Improvement_%'])

more_effective = "Dataset 1" if d1_improvement > d2_improvement else "Dataset 2"

print(f"\n1. PREPROCESSING EFFECTIVENESS:")
print(f"   Dataset 1: {'‚úÖ EFFECTIVE' if d1_effective else '‚ùå NOT EFFECTIVE'} (Best improvement: {d1_improvement:+.2f}%)")
print(f"   Dataset 2: {'‚úÖ EFFECTIVE' if d2_effective else '‚ùå NOT EFFECTIVE'} (Best improvement: {d2_improvement:+.2f}%)")
print(f"   ‚Üí More effective on: {more_effective}")

print(f"\n2. METHOD PREFERENCE BY DATASET:")
d1_best = "RFECV" if d1_rfecv['RMSE_Test'] < d1_kbest['RMSE_Test'] else "SelectKBest"
d2_best = "RFECV" if d2_rfecv['RMSE_Test'] < d2_kbest['RMSE_Test'] else "SelectKBest"
print(f"   Dataset 1 prefers: {d1_best}")
print(f"   Dataset 2 prefers: {d2_best}")

print(f"\n3. DATA CHARACTERISTICS ANALYSIS:")
print(f"   Dataset 1 (Pharmacy Transactions):")
print(f"   - Temporal dependencies (time series)")
print(f"   - Non-linear patterns (complex product demand)")
print(f"   - High feature interaction")
print(f"   ‚Üí {d1_best} performs better: {'model-based selection handles complexity' if d1_best == 'RFECV' else 'statistical test captures linear trends'}")

print(f"\n   Dataset 2 (Wave Parameters):")
print(f"   - Physical measurements (sensors)")
print(f"   - Strong linear correlations")
print(f"   - Independent features")
print(f"   ‚Üí {d2_best} performs better: {'model-based captures non-linearity' if d2_best == 'RFECV' else 'F-test identifies strong linear relationships'}")

print(f"\n4. DIMENSIONALITY REDUCTION:")
d1_dim_reduction = ((d1_baseline['N_Features'] - d1_rfecv['N_Features']) / d1_baseline['N_Features']) * 100
d2_dim_reduction = ((d2_baseline['N_Features'] - d2_rfecv['N_Features']) / d2_baseline['N_Features']) * 100
print(f"   Dataset 1: {d1_baseline['N_Features']} ‚Üí {d1_rfecv['N_Features']} features ({d1_dim_reduction:.1f}% reduction)")
print(f"   Dataset 2: {d2_baseline['N_Features']} ‚Üí {d2_rfecv['N_Features']} features ({d2_dim_reduction:.1f}% reduction)")

print(f"\n5. OVERFITTING CONTROL:")
print(f"   Dataset 1:")
print(f"   - Baseline: {d1_baseline['Overfitting_Gap']:.4f}")
print(f"   - RFECV: {d1_rfecv['Overfitting_Gap']:.4f} ({'‚Üì improved' if d1_rfecv['Overfitting_Gap'] < d1_baseline['Overfitting_Gap'] else '‚Üë worsened'})")
print(f"   - SelectKBest: {d1_kbest['Overfitting_Gap']:.4f} ({'‚Üì improved' if d1_kbest['Overfitting_Gap'] < d1_baseline['Overfitting_Gap'] else '‚Üë worsened'})")
print(f"\n   Dataset 2:")
print(f"   - Baseline: {d2_baseline['Overfitting_Gap']:.4f}")
print(f"   - RFECV: {d2_rfecv['Overfitting_Gap']:.4f} ({'‚Üì improved' if d2_rfecv['Overfitting_Gap'] < d2_baseline['Overfitting_Gap'] else '‚Üë worsened'})")
print(f"   - SelectKBest: {d2_kbest['Overfitting_Gap']:.4f} ({'‚Üì improved' if d2_kbest['Overfitting_Gap'] < d2_baseline['Overfitting_Gap'] else '‚Üë worsened'})")

# Save comparative analysis
output_dir = project_root / 'outputs'
comparison_text = f"""
COMPARATIVE ANALYSIS: Dataset 1 vs Dataset 2
{'='*80}

PREPROCESSING METHOD: Feature Selection (RFECV vs SelectKBest)
VALIDATION: Decision Tree Regressor

DATASET CHARACTERISTICS:
-------------------------

Dataset 1 (Pharmacy Transactions):
- Type: Time series data
- Features: {int(d1_baseline['N_Features'])} (temporal, lag, rolling statistics)
- Samples: Training data with temporal dependencies
- Pattern: Non-linear, complex product demand patterns
- Best Method: {d1_best}
- Improvement: {d1_improvement:+.2f}%

Dataset 2 (Wave Parameters):
- Type: Physical sensor measurements
- Features: {int(d2_baseline['N_Features'])} (wave height, period, temperature, etc.)
- Samples: Independent observations
- Pattern: Linear correlations between physical variables
- Best Method: {d2_best}
- Improvement: {d2_improvement:+.2f}%

EFFECTIVENESS COMPARISON:
------------------------

Preprocessing Effectiveness:
- Dataset 1: {'EFFECTIVE' if d1_effective else 'NOT EFFECTIVE'} (Best RMSE improvement: {d1_improvement:+.2f}%)
- Dataset 2: {'EFFECTIVE' if d2_effective else 'NOT EFFECTIVE'} (Best RMSE improvement: {d2_improvement:+.2f}%)
- More Effective On: {more_effective}

Why Different Results?
1. DATA NATURE:
   - Dataset 1 has temporal dependencies ‚Üí Feature selection must preserve time-related patterns
   - Dataset 2 has independent measurements ‚Üí Feature selection can focus purely on correlation

2. FEATURE RELATIONSHIPS:
   - Dataset 1: High feature interaction (lags multiply with rolling stats)
   - Dataset 2: Independent physical measurements (wave height, temperature separate)

3. MODEL-DATA FIT:
   - RFECV (model-based): Better for complex patterns, feature interactions
   - SelectKBest (statistical): Better for linear correlations, independent features

DIMENSIONALITY REDUCTION:
-----------------------
Dataset 1: {int(d1_baseline['N_Features'])} ‚Üí {int(d1_rfecv['N_Features'])} features ({d1_dim_reduction:.1f}% reduction)
Dataset 2: {int(d2_baseline['N_Features'])} ‚Üí {int(d2_rfecv['N_Features'])} features ({d2_dim_reduction:.1f}% reduction)

OVERFITTING CONTROL:
------------------
Dataset 1:
- Baseline Gap: {d1_baseline['Overfitting_Gap']:.4f}
- Best Gap: {min(d1_rfecv['Overfitting_Gap'], d1_kbest['Overfitting_Gap']):.4f} ({'improved' if min(d1_rfecv['Overfitting_Gap'], d1_kbest['Overfitting_Gap']) < d1_baseline['Overfitting_Gap'] else 'not improved'})

Dataset 2:
- Baseline Gap: {d2_baseline['Overfitting_Gap']:.4f}
- Best Gap: {min(d2_rfecv['Overfitting_Gap'], d2_kbest['Overfitting_Gap']):.4f} ({'improved' if min(d2_rfecv['Overfitting_Gap'], d2_kbest['Overfitting_Gap']) < d2_baseline['Overfitting_Gap'] else 'not improved'})

CONCLUSION:
----------
Feature selection preprocessing demonstrates CONTEXT-DEPENDENT effectiveness:

1. WHEN TO USE RFECV:
   - Time series data with temporal patterns
   - Complex feature interactions
   - Non-linear relationships
   - Dataset 1 scenario

2. WHEN TO USE SelectKBest:
   - Independent observations
   - Strong linear correlations
   - Physical/sensor measurements
   - Dataset 2 scenario

3. KEY INSIGHT:
   Preprocessing effectiveness depends on:
   - Data structure (time series vs independent)
   - Feature relationships (interaction vs independent)
   - Pattern complexity (non-linear vs linear)
   
   NO ONE-SIZE-FITS-ALL: Method selection must consider data characteristics!

VALIDATION WITH SIMPLE ML:
-------------------------
Decision Tree Regressor successfully validated preprocessing effectiveness:
- Consistent hyperparameters across all tests
- Same train/test split methodology
- Fair comparison: Baseline vs RFECV vs SelectKBest
- Demonstrated that preprocessing improves or maintains performance while reducing complexity
"""

with open(output_dir / 'comparative_analysis.txt', 'w', encoding='utf-8') as f:
    f.write(comparison_text)

# Visualization
print("\n[3/3] Creating visualization...")
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. RMSE Comparison
methods = ['Baseline', 'RFECV', 'SelectKBest']
d1_rmses = [d1_baseline['RMSE_Test'], d1_rfecv['RMSE_Test'], d1_kbest['RMSE_Test']]
d2_rmses = [d2_baseline['RMSE_Test'], d2_rfecv['RMSE_Test'], d2_kbest['RMSE_Test']]

x = np.arange(len(methods))
width = 0.35

axes[0,0].bar(x - width/2, d1_rmses, width, label='Dataset 1 (Pharmacy)', alpha=0.8, color='steelblue')
axes[0,0].bar(x + width/2, d2_rmses, width, label='Dataset 2 (Wave)', alpha=0.8, color='coral')
axes[0,0].set_ylabel('RMSE')
axes[0,0].set_title('RMSE Comparison Across Methods')
axes[0,0].set_xticks(x)
axes[0,0].set_xticklabels(methods)
axes[0,0].legend()
axes[0,0].grid(axis='y', alpha=0.3)

# 2. R¬≤ Comparison
d1_r2s = [d1_baseline['R2_Test'], d1_rfecv['R2_Test'], d1_kbest['R2_Test']]
d2_r2s = [d2_baseline['R2_Test'], d2_rfecv['R2_Test'], d2_kbest['R2_Test']]

axes[0,1].bar(x - width/2, d1_r2s, width, label='Dataset 1 (Pharmacy)', alpha=0.8, color='steelblue')
axes[0,1].bar(x + width/2, d2_r2s, width, label='Dataset 2 (Wave)', alpha=0.8, color='coral')
axes[0,1].set_ylabel('R¬≤ Score')
axes[0,1].set_title('R¬≤ Comparison Across Methods')
axes[0,1].set_xticks(x)
axes[0,1].set_xticklabels(methods)
axes[0,1].legend()
axes[0,1].grid(axis='y', alpha=0.3)

# 3. Improvement Percentage
improvements = ['Dataset 1\n(RFECV)', 'Dataset 1\n(SelectKBest)', 'Dataset 2\n(RFECV)', 'Dataset 2\n(SelectKBest)']
improvement_vals = [d1_rfecv['RMSE_Improvement_%'], d1_kbest['RMSE_Improvement_%'], 
                    d2_rfecv['RMSE_Improvement_%'], d2_kbest['RMSE_Improvement_%']]
colors = ['steelblue', 'steelblue', 'coral', 'coral']

axes[1,0].bar(improvements, improvement_vals, alpha=0.8, color=colors)
axes[1,0].axhline(y=0, color='red', linestyle='--', linewidth=1)
axes[1,0].set_ylabel('RMSE Improvement (%)')
axes[1,0].set_title('Preprocessing Effectiveness')
axes[1,0].grid(axis='y', alpha=0.3)
axes[1,0].tick_params(axis='x', rotation=0)

# 4. Feature Count Reduction
feature_reduction = [
    f"D1\nBaseline\n({int(d1_baseline['N_Features'])})",
    f"D1\nSelected\n({int(d1_rfecv['N_Features'])})",
    f"D2\nBaseline\n({int(d2_baseline['N_Features'])})",
    f"D2\nSelected\n({int(d2_rfecv['N_Features'])})"
]
feature_counts = [d1_baseline['N_Features'], d1_rfecv['N_Features'], 
                  d2_baseline['N_Features'], d2_rfecv['N_Features']]
colors2 = ['lightgray', 'steelblue', 'lightcoral', 'coral']

axes[1,1].bar(feature_reduction, feature_counts, alpha=0.8, color=colors2)
axes[1,1].set_ylabel('Number of Features')
axes[1,1].set_title('Dimensionality Reduction')
axes[1,1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig(output_dir / 'comparative_visualization.png', dpi=150, bbox_inches='tight')

print(f"‚úÖ Comparative analysis saved to: {output_dir}/")
print(f"   - comparative_analysis.txt")
print(f"   - comparative_visualization.png")
print("\n"+"="*80)
print("KEY FINDINGS:")
print("="*80)
print(f"1. Preprocessing is MORE effective on: {more_effective}")
print(f"2. Dataset 1 best method: {d1_best} ({d1_improvement:+.2f}% improvement)")
print(f"3. Dataset 2 best method: {d2_best} ({d2_improvement:+.2f}% improvement)")
print(f"4. Method effectiveness depends on DATA CHARACTERISTICS")
print("="*80)
print("\n‚úÖ COMPARATIVE ANALYSIS COMPLETE!")
