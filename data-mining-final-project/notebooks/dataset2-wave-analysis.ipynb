{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba07931",
   "metadata": {},
   "source": [
    "## üì¶ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df2f5e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV, mutual_info_regression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220340e",
   "metadata": {},
   "source": [
    "## üìÇ Auto-Load Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d4b126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 6 Excel files:\n",
      "  üìÑ dataset-type-2\\Gelombang (1).xlsx\n",
      "  üìÑ dataset-type-2\\Gelombang (2).xlsx\n",
      "  üìÑ dataset-type-2\\Gelombang (3).xlsx\n",
      "  üìÑ dataset-type-2\\Gelombang (4).xlsx\n",
      "  üìÑ dataset-type-2\\Gelombang (5).xlsx\n",
      "  üìÑ dataset-type-2\\Gelombang (6).xlsx\n",
      "‚úÖ Loaded dataset-type-2\\Gelombang (1).xlsx: 8741 rows, 24 columns\n",
      "‚úÖ Loaded dataset-type-2\\Gelombang (2).xlsx: 8740 rows, 24 columns\n",
      "‚úÖ Loaded dataset-type-2\\Gelombang (3).xlsx: 17548 rows, 24 columns\n",
      "‚úÖ Loaded dataset-type-2\\Gelombang (4).xlsx: 8740 rows, 24 columns\n",
      "‚úÖ Loaded dataset-type-2\\Gelombang (5).xlsx: 8740 rows, 24 columns\n",
      "‚úÖ Loaded dataset-type-2\\Gelombang (6).xlsx: 8740 rows, 24 columns\n",
      "\n",
      "üìä Total combined data: 61,249 rows, 30 columns\n",
      "\n",
      "üìã Columns: ['bandar agung_Andrean Syahrezi', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Location:', 'Teluk betung', 'Panjang', 'Kota Jawa', 'Kota agung', 'kalianda']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bandar agung_Andrean Syahrezi</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Location:</th>\n",
       "      <th>Teluk betung</th>\n",
       "      <th>Panjang</th>\n",
       "      <th>Kota Jawa</th>\n",
       "      <th>Kota agung</th>\n",
       "      <th>kalianda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Location:</td>\n",
       "      <td>bandar agung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Latitude:</td>\n",
       "      <td>-5.604619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Longitude:</td>\n",
       "      <td>105.838853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Time(UTC/GMT)</td>\n",
       "      <td>Hsig(m)</td>\n",
       "      <td>Hsig(Scale)</td>\n",
       "      <td>Hmax(m)</td>\n",
       "      <td>Hmax(Scale)</td>\n",
       "      <td>WaveDir(deg)</td>\n",
       "      <td>WaveDir(compass)</td>\n",
       "      <td>PrimSwell(m)</td>\n",
       "      <td>PrimSwell(Scale)</td>\n",
       "      <td>PrimSwellDir(deg)</td>\n",
       "      <td>...</td>\n",
       "      <td>SeaSurfaceSalinity(PSU)</td>\n",
       "      <td>WindSpeed(knots)</td>\n",
       "      <td>WindDir(deg)</td>\n",
       "      <td>WindDir(compass)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-29 00:00:00</td>\n",
       "      <td>0.08409</td>\n",
       "      <td>Smooth</td>\n",
       "      <td>0.16817</td>\n",
       "      <td>Smooth</td>\n",
       "      <td>334</td>\n",
       "      <td>NNW</td>\n",
       "      <td>0.07923</td>\n",
       "      <td>Smooth</td>\n",
       "      <td>270</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0715</td>\n",
       "      <td>1.30439</td>\n",
       "      <td>62</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bandar agung_Andrean Syahrezi    Unnamed: 1   Unnamed: 2 Unnamed: 3  \\\n",
       "0                     Location:  bandar agung          NaN        NaN   \n",
       "1                     Latitude:     -5.604619          NaN        NaN   \n",
       "2                    Longitude:    105.838853          NaN        NaN   \n",
       "3                 Time(UTC/GMT)       Hsig(m)  Hsig(Scale)    Hmax(m)   \n",
       "4           2024-07-29 00:00:00       0.08409       Smooth    0.16817   \n",
       "\n",
       "    Unnamed: 4    Unnamed: 5        Unnamed: 6    Unnamed: 7  \\\n",
       "0          NaN           NaN               NaN           NaN   \n",
       "1          NaN           NaN               NaN           NaN   \n",
       "2          NaN           NaN               NaN           NaN   \n",
       "3  Hmax(Scale)  WaveDir(deg)  WaveDir(compass)  PrimSwell(m)   \n",
       "4       Smooth           334               NNW       0.07923   \n",
       "\n",
       "         Unnamed: 8         Unnamed: 9  ...              Unnamed: 20  \\\n",
       "0               NaN                NaN  ...                      NaN   \n",
       "1               NaN                NaN  ...                      NaN   \n",
       "2               NaN                NaN  ...                      NaN   \n",
       "3  PrimSwell(Scale)  PrimSwellDir(deg)  ...  SeaSurfaceSalinity(PSU)   \n",
       "4            Smooth                270  ...                  31.0715   \n",
       "\n",
       "        Unnamed: 21   Unnamed: 22       Unnamed: 23 Location: Teluk betung  \\\n",
       "0               NaN           NaN               NaN       NaN          NaN   \n",
       "1               NaN           NaN               NaN       NaN          NaN   \n",
       "2               NaN           NaN               NaN       NaN          NaN   \n",
       "3  WindSpeed(knots)  WindDir(deg)  WindDir(compass)       NaN          NaN   \n",
       "4           1.30439            62               ENE       NaN          NaN   \n",
       "\n",
       "  Panjang Kota Jawa Kota agung kalianda  \n",
       "0     NaN       NaN        NaN      NaN  \n",
       "1     NaN       NaN        NaN      NaN  \n",
       "2     NaN       NaN        NaN      NaN  \n",
       "3     NaN       NaN        NaN      NaN  \n",
       "4     NaN       NaN        NaN      NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auto-detect all Excel files in dataset-type-2 folder\n",
    "excel_files = glob.glob('dataset-type-2/*.xlsx')\n",
    "\n",
    "print(f\"üîç Found {len(excel_files)} Excel files:\")\n",
    "for f in excel_files:\n",
    "    print(f\"  üìÑ {f}\")\n",
    "\n",
    "if len(excel_files) == 0:\n",
    "    raise FileNotFoundError(\"‚ùå No Excel files found in dataset-type-2/ folder!\")\n",
    "\n",
    "# Load and combine all Excel files\n",
    "dfs = []\n",
    "for file in excel_files:\n",
    "    try:\n",
    "        df_temp = pd.read_excel(file)\n",
    "        dfs.append(df_temp)\n",
    "        print(f\"‚úÖ Loaded {file}: {len(df_temp)} rows, {len(df_temp.columns)} columns\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file}: {e}\")\n",
    "\n",
    "# Combine all dataframes\n",
    "df_raw = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"\\nüìä Total combined data: {len(df_raw):,} rows, {len(df_raw.columns)} columns\")\n",
    "print(f\"\\nüìã Columns: {list(df_raw.columns)}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f13663f",
   "metadata": {},
   "source": [
    "## ü§ñ Auto-Detect Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d083e9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "arg must be a list, tuple, 1-d array, or Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Convert all remaining columns to numeric\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_clean\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 31\u001b[0m     df_clean[col] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoerce\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Remove rows with NaN values\u001b[39;00m\n\u001b[0;32m     34\u001b[0m df_clean \u001b[38;5;241m=\u001b[39m df_clean\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[1;32mc:\\Users\\muham\\OneDrive\\Desktop\\data-mining-uas\\data-mining-final-project\\.venv\\lib\\site-packages\\pandas\\core\\tools\\numeric.py:209\u001b[0m, in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast, dtype_backend)\u001b[0m\n\u001b[0;32m    207\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([arg], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg must be a list, tuple, 1-d array, or Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     values \u001b[38;5;241m=\u001b[39m arg\n",
      "\u001b[1;31mTypeError\u001b[0m: arg must be a list, tuple, 1-d array, or Series"
     ]
    }
   ],
   "source": [
    "# The data has metadata rows at the top, we need to extract the actual data\n",
    "# Row 3 contains the column names, row 4+ contains the data\n",
    "# We need to reload the data properly\n",
    "\n",
    "# Find the header row (row with \"Time(UTC/GMT)\")\n",
    "header_row = None\n",
    "for idx, row in df_raw.iterrows():\n",
    "    if 'Time(UTC/GMT)' in str(row.values):\n",
    "        header_row = idx\n",
    "        break\n",
    "\n",
    "if header_row is None:\n",
    "    raise ValueError(\"‚ùå Could not find header row with 'Time(UTC/GMT)'\")\n",
    "\n",
    "# Extract column names from header row\n",
    "columns = df_raw.iloc[header_row].values.tolist()\n",
    "# Extract data starting from the row after header\n",
    "data = df_raw.iloc[header_row + 1:].values\n",
    "\n",
    "# Create clean dataframe\n",
    "df_clean = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Remove 'Time(UTC/GMT)' column and text columns (Scale, compass)\n",
    "text_cols = ['Time(UTC/GMT)', 'Hsig(Scale)', 'Hmax(Scale)', 'WaveDir(compass)', \n",
    "             'PrimSwell(Scale)', 'PrimSwellDir(compass)', 'WindSea(Scale)', \n",
    "             'WindSeaDir(compass)', 'SurfCurrentDir(compass)', 'WindDir(compass)']\n",
    "df_clean = df_clean.drop(columns=[col for col in text_cols if col in df_clean.columns], errors='ignore')\n",
    "\n",
    "# Convert all remaining columns to numeric\n",
    "for col in df_clean.columns:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# Remove rows with NaN values\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "# Auto-detect numeric columns\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"üî¢ Found {len(numeric_cols)} numeric columns:\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"  ‚Ä¢ {col}\")\n",
    "\n",
    "if len(numeric_cols) < 2:\n",
    "    raise ValueError(\"‚ùå Need at least 2 numeric columns (1 target + 1 feature)\")\n",
    "\n",
    "# Auto-assign target (last numeric column) and features (all others)\n",
    "target_col = numeric_cols[-1]\n",
    "feature_cols = numeric_cols[:-1]\n",
    "\n",
    "print(f\"\\nüéØ Auto-detected Target: {target_col}\")\n",
    "print(f\"üìä Auto-detected Features ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "# Extract features and target\n",
    "df = df_clean[numeric_cols].copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Clean data: {len(df):,} rows (after removing NaN)\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eaab2b",
   "metadata": {},
   "source": [
    "## üéØ Prepare Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d51b4757",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Split features and target\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[feature_cols]\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target_col]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train/test split (80/20)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "# Train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"üì¶ Train set: {len(X_train):,} rows\")\n",
    "print(f\"üì¶ Test set: {len(X_test):,} rows\")\n",
    "print(f\"\\nüìä Target ({target_col}) statistics:\")\n",
    "print(f\"  - Mean: {y_train.mean():.4f}\")\n",
    "print(f\"  - Std: {y_train.std():.4f}\")\n",
    "print(f\"  - Min: {y_train.min():.4f}\")\n",
    "print(f\"  - Max: {y_train.max():.4f}\")\n",
    "\n",
    "# Optional: Standardize features for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_cols)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_cols)\n",
    "\n",
    "print(\"\\n‚úÖ Data standardized (mean=0, std=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4940c5",
   "metadata": {},
   "source": [
    "## üî¨ Experiment 1: RFECV Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üî¨ EXPERIMENT 1: RFECV + LightGBM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Base estimator for RFECV\n",
    "base_estimator = lgb.LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# RFECV - automatically finds optimal number of features\n",
    "print(\"\\n‚è≥ Running RFECV... (this may take a few minutes)\")\n",
    "start_time = time.time()\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=base_estimator,\n",
    "    step=1,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "rfecv_time = time.time() - start_time\n",
    "\n",
    "# Get selected features\n",
    "rfecv_features = X_train_scaled.columns[rfecv.support_].tolist()\n",
    "print(f\"\\n‚úÖ RFECV completed in {rfecv_time:.2f} seconds\")\n",
    "print(f\"üéØ Optimal number of features: {rfecv.n_features_}\")\n",
    "print(f\"üìä Selected features: {rfecv_features}\")\n",
    "\n",
    "# Transform data\n",
    "X_train_rfecv = rfecv.transform(X_train_scaled)\n",
    "X_test_rfecv = rfecv.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e27fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with selected features\n",
    "print(\"\\nüèãÔ∏è Training LightGBM with RFECV features...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model_rfecv = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model_rfecv.fit(X_train_rfecv, y_train)\n",
    "train_time_rfecv = time.time() - start_time\n",
    "\n",
    "# Predictions\n",
    "y_pred_rfecv = model_rfecv.predict(X_test_rfecv)\n",
    "\n",
    "# Metrics\n",
    "rmse_rfecv = np.sqrt(mean_squared_error(y_test, y_pred_rfecv))\n",
    "mae_rfecv = mean_absolute_error(y_test, y_pred_rfecv)\n",
    "r2_rfecv = r2_score(y_test, y_pred_rfecv)\n",
    "\n",
    "print(f\"\\nüìä RFECV Results:\")\n",
    "print(f\"  ‚è±Ô∏è  Total time: {rfecv_time + train_time_rfecv:.2f}s\")\n",
    "print(f\"  üéØ Features used: {rfecv.n_features_}\")\n",
    "print(f\"  üìâ RMSE: {rmse_rfecv:.4f}\")\n",
    "print(f\"  üìâ MAE: {mae_rfecv:.4f}\")\n",
    "print(f\"  üìà R¬≤: {r2_rfecv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4aa335",
   "metadata": {},
   "source": [
    "## üî¨ Experiment 2: Mutual Information Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üî¨ EXPERIMENT 2: Mutual Information + LightGBM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate mutual information scores\n",
    "print(\"\\n‚è≥ Calculating Mutual Information scores...\")\n",
    "start_time = time.time()\n",
    "\n",
    "mi_scores = mutual_info_regression(X_train_scaled, y_train, random_state=42, n_jobs=-1)\n",
    "mi_time = time.time() - start_time\n",
    "\n",
    "# Create feature importance dataframe\n",
    "mi_df = pd.DataFrame({\n",
    "    'feature': X_train_scaled.columns,\n",
    "    'mi_score': mi_scores\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "print(f\"\\n‚úÖ MI calculation completed in {mi_time:.2f} seconds\")\n",
    "print(f\"\\nüìä All features ranked by MI score:\")\n",
    "print(mi_df.to_string(index=False))\n",
    "\n",
    "# Select top k features (same number as RFECV for fair comparison)\n",
    "top_k = rfecv.n_features_\n",
    "mi_features = mi_df.head(top_k)['feature'].tolist()\n",
    "\n",
    "print(f\"\\nüéØ Selected top {top_k} features: {mi_features}\")\n",
    "\n",
    "# Transform data\n",
    "X_train_mi = X_train_scaled[mi_features]\n",
    "X_test_mi = X_test_scaled[mi_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a72d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with MI features\n",
    "print(\"\\nüèãÔ∏è Training LightGBM with MI features...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model_mi = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model_mi.fit(X_train_mi, y_train)\n",
    "train_time_mi = time.time() - start_time\n",
    "\n",
    "# Predictions\n",
    "y_pred_mi = model_mi.predict(X_test_mi)\n",
    "\n",
    "# Metrics\n",
    "rmse_mi = np.sqrt(mean_squared_error(y_test, y_pred_mi))\n",
    "mae_mi = mean_absolute_error(y_test, y_pred_mi)\n",
    "r2_mi = r2_score(y_test, y_pred_mi)\n",
    "\n",
    "print(f\"\\nüìä Mutual Information Results:\")\n",
    "print(f\"  ‚è±Ô∏è  Total time: {mi_time + train_time_mi:.2f}s\")\n",
    "print(f\"  üéØ Features used: {top_k}\")\n",
    "print(f\"  üìâ RMSE: {rmse_mi:.4f}\")\n",
    "print(f\"  üìâ MAE: {mae_mi:.4f}\")\n",
    "print(f\"  üìà R¬≤: {r2_mi:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517717e",
   "metadata": {},
   "source": [
    "## üìä Comparison & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffbec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results = pd.DataFrame({\n",
    "    'Method': ['RFECV', 'Mutual Information'],\n",
    "    'RMSE': [rmse_rfecv, rmse_mi],\n",
    "    'MAE': [mae_rfecv, mae_mi],\n",
    "    'R2': [r2_rfecv, r2_mi],\n",
    "    'Time (s)': [rfecv_time + train_time_rfecv, mi_time + train_time_mi],\n",
    "    'Num Features': [rfecv.n_features_, top_k]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FINAL COMPARISON: RFECV vs Mutual Information\")\n",
    "print(\"=\"*80)\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Determine winner\n",
    "print(\"\\nüèÜ WINNER ANALYSIS:\")\n",
    "if rmse_rfecv < rmse_mi:\n",
    "    print(f\"  ü•á RFECV wins on RMSE ({rmse_rfecv:.4f} < {rmse_mi:.4f})\")\n",
    "    diff = ((rmse_mi - rmse_rfecv) / rmse_mi) * 100\n",
    "    print(f\"     ‚Üí {diff:.2f}% better than MI\")\n",
    "else:\n",
    "    print(f\"  ü•á Mutual Information wins on RMSE ({rmse_mi:.4f} < {rmse_rfecv:.4f})\")\n",
    "    diff = ((rmse_rfecv - rmse_mi) / rmse_rfecv) * 100\n",
    "    print(f\"     ‚Üí {diff:.2f}% better than RFECV\")\n",
    "\n",
    "if r2_rfecv > r2_mi:\n",
    "    print(f\"  ü•á RFECV wins on R¬≤ ({r2_rfecv:.4f} > {r2_mi:.4f})\")\n",
    "else:\n",
    "    print(f\"  ü•á Mutual Information wins on R¬≤ ({r2_mi:.4f} > {r2_rfecv:.4f})\")\n",
    "\n",
    "if (rfecv_time + train_time_rfecv) < (mi_time + train_time_mi):\n",
    "    print(f\"  ‚ö° RFECV is faster ({rfecv_time + train_time_rfecv:.2f}s < {mi_time + train_time_mi:.2f}s)\")\n",
    "else:\n",
    "    ratio = (rfecv_time + train_time_rfecv) / (mi_time + train_time_mi)\n",
    "    print(f\"  ‚ö° Mutual Information is faster ({mi_time + train_time_mi:.2f}s < {rfecv_time + train_time_rfecv:.2f}s)\")\n",
    "    print(f\"     ‚Üí {ratio:.1f}x faster than RFECV\")\n",
    "\n",
    "# Save results\n",
    "results.to_csv('results_dataset2_wave.csv', index=False)\n",
    "print(\"\\nüíæ Results saved to: results_dataset2_wave.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f1fc2",
   "metadata": {},
   "source": [
    "## üìà Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70deb47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle(f'Dataset 2: Feature Selection Comparison (Target: {target_col})', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "methods = ['RFECV', 'MI']\n",
    "colors = ['#9b59b6', '#f39c12']\n",
    "\n",
    "# Plot 1: RMSE\n",
    "ax1 = axes[0, 0]\n",
    "ax1.bar(methods, [rmse_rfecv, rmse_mi], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('RMSE', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Root Mean Squared Error (Lower is Better)', fontsize=12)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate([rmse_rfecv, rmse_mi]):\n",
    "    ax1.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 2: R¬≤\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(methods, [r2_rfecv, r2_mi], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('R¬≤ Score', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('R¬≤ Score (Higher is Better)', fontsize=12)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_ylim([min(r2_rfecv, r2_mi) * 0.95, max(r2_rfecv, r2_mi) * 1.05])\n",
    "for i, v in enumerate([r2_rfecv, r2_mi]):\n",
    "    ax2.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 3: Training Time\n",
    "ax3 = axes[1, 0]\n",
    "times = [rfecv_time + train_time_rfecv, mi_time + train_time_mi]\n",
    "ax3.bar(methods, times, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax3.set_ylabel('Time (seconds)', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Total Processing Time (Lower is Better)', fontsize=12)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(times):\n",
    "    ax3.text(i, v, f'{v:.2f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 4: MAE\n",
    "ax4 = axes[1, 1]\n",
    "ax4.bar(methods, [mae_rfecv, mae_mi], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax4.set_ylabel('MAE', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Mean Absolute Error (Lower is Better)', fontsize=12)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate([mae_rfecv, mae_mi]):\n",
    "    ax4.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_dataset2_wave.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nüìä Visualization saved to: comparison_dataset2_wave.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db11e48",
   "metadata": {},
   "source": [
    "## üîç Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5aed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare selected features\n",
    "print(\"\\nüìä FEATURE SELECTION COMPARISON:\")\n",
    "print(\"\\nüîπ RFECV Selected Features:\")\n",
    "for i, feat in enumerate(rfecv_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "print(\"\\nüîπ Mutual Information Top Features:\")\n",
    "for i, row in mi_df.head(top_k).iterrows():\n",
    "    print(f\"  {i+1}. {row['feature']} (score: {row['mi_score']:.4f})\")\n",
    "\n",
    "# Find common features\n",
    "common_features = set(rfecv_features) & set(mi_features)\n",
    "print(f\"\\nü§ù Common Features ({len(common_features)}):\")\n",
    "for feat in common_features:\n",
    "    print(f\"  ‚úì {feat}\")\n",
    "\n",
    "# Unique features\n",
    "rfecv_only = set(rfecv_features) - set(mi_features)\n",
    "mi_only = set(mi_features) - set(rfecv_features)\n",
    "\n",
    "if rfecv_only:\n",
    "    print(f\"\\nüîπ RFECV-only features ({len(rfecv_only)}):\")\n",
    "    for feat in rfecv_only:\n",
    "        print(f\"  ‚Ä¢ {feat}\")\n",
    "        \n",
    "if mi_only:\n",
    "    print(f\"\\nüîπ MI-only features ({len(mi_only)}):\")\n",
    "    for feat in mi_only:\n",
    "        print(f\"  ‚Ä¢ {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3786f4",
   "metadata": {},
   "source": [
    "## üìà Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f29e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle(f'Actual vs Predicted: {target_col}', fontsize=16, fontweight='bold')\n",
    "\n",
    "# RFECV\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test, y_pred_rfecv, alpha=0.5, color='#9b59b6', edgecolors='black', linewidth=0.5)\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect prediction')\n",
    "ax1.set_xlabel('Actual', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Predicted', fontsize=12, fontweight='bold')\n",
    "ax1.set_title(f'RFECV (R¬≤={r2_rfecv:.4f})', fontsize=12)\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Mutual Information\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(y_test, y_pred_mi, alpha=0.5, color='#f39c12', edgecolors='black', linewidth=0.5)\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect prediction')\n",
    "ax2.set_xlabel('Actual', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Predicted', fontsize=12, fontweight='bold')\n",
    "ax2.set_title(f'Mutual Information (R¬≤={r2_mi:.4f})', fontsize=12)\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('predictions_dataset2_wave.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nüìä Prediction plot saved to: predictions_dataset2_wave.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ad1c4",
   "metadata": {},
   "source": [
    "## üìù Conclusion & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a507b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù KESIMPULAN & REKOMENDASI - DATASET 2 (WAVE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate percentage differences\n",
    "rmse_diff = abs(rmse_rfecv - rmse_mi) / min(rmse_rfecv, rmse_mi) * 100\n",
    "r2_diff = abs(r2_rfecv - r2_mi) / max(r2_rfecv, r2_mi) * 100\n",
    "time_diff = abs((rfecv_time + train_time_rfecv) - (mi_time + train_time_mi)) / min(rfecv_time + train_time_rfecv, mi_time + train_time_mi) * 100\n",
    "\n",
    "print(f\"\\nüìä Performance Differences:\")\n",
    "print(f\"  ‚Ä¢ RMSE difference: {rmse_diff:.2f}%\")\n",
    "print(f\"  ‚Ä¢ R¬≤ difference: {r2_diff:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Time difference: {time_diff:.2f}%\")\n",
    "\n",
    "print(f\"\\nüéØ Dataset Characteristics:\")\n",
    "print(f\"  ‚Ä¢ Target variable: {target_col}\")\n",
    "print(f\"  ‚Ä¢ Total features available: {len(feature_cols)}\")\n",
    "print(f\"  ‚Ä¢ Features selected: {top_k}\")\n",
    "print(f\"  ‚Ä¢ Selection rate: {(top_k/len(feature_cols)*100):.1f}%\")\n",
    "\n",
    "print(f\"\\nüèÜ Recommendations:\")\n",
    "\n",
    "# Overall winner\n",
    "if rmse_rfecv < rmse_mi and r2_rfecv > r2_mi:\n",
    "    print(\"  ‚úÖ RFECV is CLEARLY BETTER for this dataset\")\n",
    "    print(\"     ‚Üí Better accuracy on both RMSE and R¬≤\")\n",
    "    print(\"     ‚Üí Use RFECV for final model deployment\")\n",
    "elif rmse_mi < rmse_rfecv and r2_mi > r2_rfecv:\n",
    "    print(\"  ‚úÖ Mutual Information is CLEARLY BETTER for this dataset\")\n",
    "    print(\"     ‚Üí Better accuracy on both RMSE and R¬≤\")\n",
    "    print(\"     ‚Üí Use MI for final model deployment\")\n",
    "else:\n",
    "    print(\"  ‚öñÔ∏è Mixed results - choose based on priority:\")\n",
    "    if rmse_rfecv < rmse_mi:\n",
    "        print(\"     ‚Üí RFECV better for minimizing prediction errors (RMSE)\")\n",
    "    else:\n",
    "        print(\"     ‚Üí MI better for minimizing prediction errors (RMSE)\")\n",
    "    if r2_rfecv > r2_mi:\n",
    "        print(\"     ‚Üí RFECV better for explaining variance (R¬≤)\")\n",
    "    else:\n",
    "        print(\"     ‚Üí MI better for explaining variance (R¬≤)\")\n",
    "\n",
    "# Speed consideration\n",
    "if (mi_time + train_time_mi) < (rfecv_time + train_time_rfecv):\n",
    "    speed_ratio = (rfecv_time + train_time_rfecv) / (mi_time + train_time_mi)\n",
    "    print(f\"\\n  ‚ö° Speed Advantage: MI is {speed_ratio:.1f}x FASTER\")\n",
    "    if speed_ratio > 2:\n",
    "        print(\"     ‚Üí Consider MI if speed is critical\")\n",
    "\n",
    "# Feature agreement\n",
    "agreement = len(common_features) / top_k * 100\n",
    "print(f\"\\n  ü§ù Feature Agreement: {agreement:.1f}%\")\n",
    "if agreement > 70:\n",
    "    print(\"     ‚Üí Both methods largely agree on important features\")\n",
    "elif agreement > 40:\n",
    "    print(\"     ‚Üí Moderate agreement - features have different importance perspectives\")\n",
    "else:\n",
    "    print(\"     ‚Üí Low agreement - methods see importance very differently\")\n",
    "\n",
    "print(f\"\\nüí° Best Practice for Wave Data:\")\n",
    "print(\"  1Ô∏è‚É£ Start with MI for quick feature exploration\")\n",
    "print(\"  2Ô∏è‚É£ Validate with RFECV for robust selection\")\n",
    "print(\"  3Ô∏è‚É£ Use ensemble of both selections for maximum robustness\")\n",
    "print(\"  4Ô∏è‚É£ Consider domain knowledge to validate selected features\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis Complete for Dataset 2!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-mining-final-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
