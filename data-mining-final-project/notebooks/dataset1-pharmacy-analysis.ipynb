{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3e8f38",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV, mutual_info_regression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"âœ… Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe399ba8",
   "metadata": {},
   "source": [
    "## ğŸ“‚ Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a076ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSV files\n",
    "files = [\n",
    "    'dataset-type-1/2021.csv',\n",
    "    'dataset-type-1/2022.csv',\n",
    "    'dataset-type-1/2023.csv',\n",
    "    'dataset-type-1/A2021.csv',\n",
    "    'dataset-type-1/A2022.csv',\n",
    "    'dataset-type-1/A2023.csv'\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    try:\n",
    "        df_temp = pd.read_csv(file)\n",
    "        dfs.append(df_temp)\n",
    "        print(f\"âœ… Loaded {file}: {len(df_temp)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading {file}: {e}\")\n",
    "\n",
    "# Combine all data\n",
    "df_raw = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"\\nğŸ“Š Total data: {len(df_raw):,} rows\")\n",
    "print(f\"ğŸ“… Columns: {list(df_raw.columns)}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d7cc4",
   "metadata": {},
   "source": [
    "## ğŸ”§ Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d273a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns untuk konsistensi\n",
    "df = df_raw.copy()\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "# Standardize column names\n",
    "column_mapping = {\n",
    "    'KODE': 'KODE_BARANG',\n",
    "    'TANGGAL': 'TANGGAL',\n",
    "    'QTY_MSK': 'QTY_MSK',\n",
    "    'NILAI_MSK': 'NILAI_MSK',\n",
    "    'QTY_KLR': 'QTY_KLR',\n",
    "    'NILAI_KLR': 'NILAI_KLR'\n",
    "}\n",
    "\n",
    "# Parse dates\n",
    "df['TANGGAL'] = pd.to_datetime(df['TANGGAL'], format='%d-%m-%y', errors='coerce')\n",
    "\n",
    "# Remove invalid dates\n",
    "df = df.dropna(subset=['TANGGAL'])\n",
    "\n",
    "# Fill missing values\n",
    "df['QTY_MSK'] = df['QTY_MSK'].fillna(0)\n",
    "df['QTY_KLR'] = df['QTY_KLR'].fillna(0)\n",
    "df['NILAI_MSK'] = df['NILAI_MSK'].fillna(0)\n",
    "df['NILAI_KLR'] = df['NILAI_KLR'].fillna(0)\n",
    "\n",
    "print(f\"âœ… After preprocessing: {len(df):,} rows\")\n",
    "print(f\"ğŸ“… Date range: {df['TANGGAL'].min()} to {df['TANGGAL'].max()}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa4908",
   "metadata": {},
   "source": [
    "## ğŸ¯ Select Top Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed03173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze top products by output volume\n",
    "top_n = 30  # Ambil top 30 products untuk efisiensi\n",
    "\n",
    "product_volume = df.groupby('KODE_BARANG')['QTY_KLR'].sum().sort_values(ascending=False)\n",
    "top_products = product_volume.head(top_n).index.tolist()\n",
    "\n",
    "print(f\"ğŸ” Top {top_n} products by volume:\")\n",
    "print(product_volume.head(top_n))\n",
    "\n",
    "# Filter untuk top products only\n",
    "df_filtered = df[df['KODE_BARANG'].isin(top_products)].copy()\n",
    "print(f\"\\nâœ… Filtered data: {len(df_filtered):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f4730",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by product and date\n",
    "df_filtered = df_filtered.sort_values(['KODE_BARANG', 'TANGGAL']).reset_index(drop=True)\n",
    "\n",
    "# Create daily aggregations\n",
    "daily_agg = df_filtered.groupby(['KODE_BARANG', 'TANGGAL']).agg({\n",
    "    'QTY_MSK': ['sum', 'mean'],\n",
    "    'QTY_KLR': ['sum', 'mean'],\n",
    "    'NILAI_MSK': ['sum', 'mean'],\n",
    "    'NILAI_KLR': ['sum', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "daily_agg.columns = ['_'.join(col).strip('_') for col in daily_agg.columns.values]\n",
    "daily_agg.columns = ['product', 'date', 'qty_in_sum', 'qty_in_mean', \n",
    "                     'qty_out_sum', 'qty_out_mean', 'value_in_sum', \n",
    "                     'value_in_mean', 'value_out_sum', 'value_out_mean']\n",
    "\n",
    "print(f\"âœ… Daily aggregations: {len(daily_agg):,} rows\")\n",
    "daily_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97413293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add temporal features\n",
    "daily_agg['day'] = daily_agg['date'].dt.day\n",
    "daily_agg['month'] = daily_agg['date'].dt.month\n",
    "daily_agg['day_of_week'] = daily_agg['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "daily_agg['week_of_year'] = daily_agg['date'].dt.isocalendar().week\n",
    "\n",
    "# Add lag features (historical data)\n",
    "for lag in [1, 2, 3, 7]:\n",
    "    daily_agg[f'qty_in_lag{lag}'] = daily_agg.groupby('product')['qty_in_sum'].shift(lag)\n",
    "    daily_agg[f'qty_out_lag{lag}'] = daily_agg.groupby('product')['qty_out_sum'].shift(lag)\n",
    "\n",
    "# Add rolling statistics (7-day window)\n",
    "daily_agg['qty_in_roll7'] = daily_agg.groupby('product')['qty_in_sum'].transform(\n",
    "    lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    ")\n",
    "daily_agg['qty_out_roll7'] = daily_agg.groupby('product')['qty_out_sum'].transform(\n",
    "    lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "print(\"âœ… Feature engineering completed!\")\n",
    "print(f\"ğŸ“Š Total features: {len(daily_agg.columns)}\")\n",
    "print(f\"\\nFeatures: {list(daily_agg.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990f8ec",
   "metadata": {},
   "source": [
    "## ğŸ¯ Prepare Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b49f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target_col = 'qty_out_sum'  # Predict current day output\n",
    "\n",
    "# Features to use (exclude target, identifiers, and date)\n",
    "exclude_cols = ['product', 'date', target_col, 'qty_out_mean', 'value_out_sum', 'value_out_mean']\n",
    "feature_cols = [col for col in daily_agg.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"ğŸ¯ Target: {target_col}\")\n",
    "print(f\"ğŸ“Š Features ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "# Remove rows with NaN (due to lag features)\n",
    "df_clean = daily_agg.dropna().copy()\n",
    "print(f\"\\nâœ… Clean data: {len(df_clean):,} rows (after removing NaN)\")\n",
    "\n",
    "# Split features and target\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean[target_col]\n",
    "\n",
    "# Train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=False  # shuffle=False for time series\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“¦ Train set: {len(X_train):,} rows\")\n",
    "print(f\"ğŸ“¦ Test set: {len(X_test):,} rows\")\n",
    "print(f\"\\nğŸ“Š Target statistics:\")\n",
    "print(f\"  - Mean: {y_train.mean():.2f}\")\n",
    "print(f\"  - Std: {y_train.std():.2f}\")\n",
    "print(f\"  - Min: {y_train.min():.2f}\")\n",
    "print(f\"  - Max: {y_train.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd445762",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Experiment 1: RFECV Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c111838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”¬ EXPERIMENT 1: RFECV + LightGBM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Base estimator for RFECV\n",
    "base_estimator = lgb.LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# RFECV - automatically finds optimal number of features\n",
    "print(\"\\nâ³ Running RFECV... (this may take a few minutes)\")\n",
    "start_time = time.time()\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=base_estimator,\n",
    "    step=1,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "rfecv_time = time.time() - start_time\n",
    "\n",
    "# Get selected features\n",
    "rfecv_features = X_train.columns[rfecv.support_].tolist()\n",
    "print(f\"\\nâœ… RFECV completed in {rfecv_time:.2f} seconds\")\n",
    "print(f\"ğŸ¯ Optimal number of features: {rfecv.n_features_}\")\n",
    "print(f\"ğŸ“Š Selected features: {rfecv_features}\")\n",
    "\n",
    "# Transform data\n",
    "X_train_rfecv = rfecv.transform(X_train)\n",
    "X_test_rfecv = rfecv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with selected features\n",
    "print(\"\\nğŸ‹ï¸ Training LightGBM with RFECV features...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model_rfecv = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model_rfecv.fit(X_train_rfecv, y_train)\n",
    "train_time_rfecv = time.time() - start_time\n",
    "\n",
    "# Predictions\n",
    "y_pred_rfecv = model_rfecv.predict(X_test_rfecv)\n",
    "\n",
    "# Metrics\n",
    "rmse_rfecv = np.sqrt(mean_squared_error(y_test, y_pred_rfecv))\n",
    "mae_rfecv = mean_absolute_error(y_test, y_pred_rfecv)\n",
    "r2_rfecv = r2_score(y_test, y_pred_rfecv)\n",
    "\n",
    "print(f\"\\nğŸ“Š RFECV Results:\")\n",
    "print(f\"  â±ï¸  Total time: {rfecv_time + train_time_rfecv:.2f}s\")\n",
    "print(f\"  ğŸ¯ Features used: {rfecv.n_features_}\")\n",
    "print(f\"  ğŸ“‰ RMSE: {rmse_rfecv:.4f}\")\n",
    "print(f\"  ğŸ“‰ MAE: {mae_rfecv:.4f}\")\n",
    "print(f\"  ğŸ“ˆ RÂ²: {r2_rfecv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e5aa2",
   "metadata": {},
   "source": [
    "## ğŸ”¬ Experiment 2: Mutual Information Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”¬ EXPERIMENT 2: Mutual Information + LightGBM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate mutual information scores\n",
    "print(\"\\nâ³ Calculating Mutual Information scores...\")\n",
    "start_time = time.time()\n",
    "\n",
    "mi_scores = mutual_info_regression(X_train, y_train, random_state=42, n_jobs=-1)\n",
    "mi_time = time.time() - start_time\n",
    "\n",
    "# Create feature importance dataframe\n",
    "mi_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'mi_score': mi_scores\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "print(f\"\\nâœ… MI calculation completed in {mi_time:.2f} seconds\")\n",
    "print(f\"\\nğŸ“Š Top 10 features by MI score:\")\n",
    "print(mi_df.head(10))\n",
    "\n",
    "# Select top k features (same number as RFECV for fair comparison)\n",
    "top_k = rfecv.n_features_\n",
    "mi_features = mi_df.head(top_k)['feature'].tolist()\n",
    "\n",
    "print(f\"\\nğŸ¯ Selected top {top_k} features: {mi_features}\")\n",
    "\n",
    "# Transform data\n",
    "X_train_mi = X_train[mi_features]\n",
    "X_test_mi = X_test[mi_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2520f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with MI features\n",
    "print(\"\\nğŸ‹ï¸ Training LightGBM with MI features...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model_mi = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model_mi.fit(X_train_mi, y_train)\n",
    "train_time_mi = time.time() - start_time\n",
    "\n",
    "# Predictions\n",
    "y_pred_mi = model_mi.predict(X_test_mi)\n",
    "\n",
    "# Metrics\n",
    "rmse_mi = np.sqrt(mean_squared_error(y_test, y_pred_mi))\n",
    "mae_mi = mean_absolute_error(y_test, y_pred_mi)\n",
    "r2_mi = r2_score(y_test, y_pred_mi)\n",
    "\n",
    "print(f\"\\nğŸ“Š Mutual Information Results:\")\n",
    "print(f\"  â±ï¸  Total time: {mi_time + train_time_mi:.2f}s\")\n",
    "print(f\"  ğŸ¯ Features used: {top_k}\")\n",
    "print(f\"  ğŸ“‰ RMSE: {rmse_mi:.4f}\")\n",
    "print(f\"  ğŸ“‰ MAE: {mae_mi:.4f}\")\n",
    "print(f\"  ğŸ“ˆ RÂ²: {r2_mi:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17684538",
   "metadata": {},
   "source": [
    "## ğŸ“Š Comparison & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c92ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results = pd.DataFrame({\n",
    "    'Method': ['RFECV', 'Mutual Information'],\n",
    "    'RMSE': [rmse_rfecv, rmse_mi],\n",
    "    'MAE': [mae_rfecv, mae_mi],\n",
    "    'R2': [r2_rfecv, r2_mi],\n",
    "    'Time (s)': [rfecv_time + train_time_rfecv, mi_time + train_time_mi],\n",
    "    'Num Features': [rfecv.n_features_, top_k]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š FINAL COMPARISON: RFECV vs Mutual Information\")\n",
    "print(\"=\"*80)\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Determine winner\n",
    "print(\"\\nğŸ† WINNER ANALYSIS:\")\n",
    "if rmse_rfecv < rmse_mi:\n",
    "    print(f\"  ğŸ¥‡ RFECV wins on RMSE ({rmse_rfecv:.4f} < {rmse_mi:.4f})\")\n",
    "else:\n",
    "    print(f\"  ğŸ¥‡ Mutual Information wins on RMSE ({rmse_mi:.4f} < {rmse_rfecv:.4f})\")\n",
    "\n",
    "if r2_rfecv > r2_mi:\n",
    "    print(f\"  ğŸ¥‡ RFECV wins on RÂ² ({r2_rfecv:.4f} > {r2_mi:.4f})\")\n",
    "else:\n",
    "    print(f\"  ğŸ¥‡ Mutual Information wins on RÂ² ({r2_mi:.4f} > {r2_rfecv:.4f})\")\n",
    "\n",
    "if (rfecv_time + train_time_rfecv) < (mi_time + train_time_mi):\n",
    "    print(f\"  âš¡ RFECV is faster ({rfecv_time + train_time_rfecv:.2f}s < {mi_time + train_time_mi:.2f}s)\")\n",
    "else:\n",
    "    print(f\"  âš¡ Mutual Information is faster ({mi_time + train_time_mi:.2f}s < {rfecv_time + train_time_rfecv:.2f}s)\")\n",
    "\n",
    "# Save results\n",
    "results.to_csv('results_dataset1_pharmacy.csv', index=False)\n",
    "print(\"\\nğŸ’¾ Results saved to: results_dataset1_pharmacy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471fc5a",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Dataset 1: Feature Selection Comparison (RFECV vs MI)', fontsize=16, fontweight='bold')\n",
    "\n",
    "methods = ['RFECV', 'MI']\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "# Plot 1: RMSE\n",
    "ax1 = axes[0, 0]\n",
    "ax1.bar(methods, [rmse_rfecv, rmse_mi], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('RMSE', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Root Mean Squared Error (Lower is Better)', fontsize=12)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate([rmse_rfecv, rmse_mi]):\n",
    "    ax1.text(i, v, f'{v:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 2: RÂ²\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(methods, [r2_rfecv, r2_mi], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('RÂ² Score', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('RÂ² Score (Higher is Better)', fontsize=12)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate([r2_rfecv, r2_mi]):\n",
    "    ax2.text(i, v, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 3: Training Time\n",
    "ax3 = axes[1, 0]\n",
    "times = [rfecv_time + train_time_rfecv, mi_time + train_time_mi]\n",
    "ax3.bar(methods, times, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax3.set_ylabel('Time (seconds)', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Total Processing Time (Lower is Better)', fontsize=12)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(times):\n",
    "    ax3.text(i, v, f'{v:.2f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 4: MAE\n",
    "ax4 = axes[1, 1]\n",
    "ax4.bar(methods, [mae_rfecv, mae_mi], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax4.set_ylabel('MAE', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Mean Absolute Error (Lower is Better)', fontsize=12)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate([mae_rfecv, mae_mi]):\n",
    "    ax4.text(i, v, f'{v:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_dataset1_pharmacy.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nğŸ“Š Visualization saved to: comparison_dataset1_pharmacy.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f0829",
   "metadata": {},
   "source": [
    "## ğŸ” Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare selected features\n",
    "print(\"\\nğŸ“Š FEATURE SELECTION COMPARISON:\")\n",
    "print(\"\\nğŸ”¹ RFECV Selected Features:\")\n",
    "for i, feat in enumerate(rfecv_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "print(\"\\nğŸ”¹ Mutual Information Top Features:\")\n",
    "for i, row in mi_df.head(top_k).iterrows():\n",
    "    print(f\"  {i+1}. {row['feature']} (score: {row['mi_score']:.4f})\")\n",
    "\n",
    "# Find common features\n",
    "common_features = set(rfecv_features) & set(mi_features)\n",
    "print(f\"\\nğŸ¤ Common Features ({len(common_features)}): {common_features}\")\n",
    "\n",
    "# Unique features\n",
    "rfecv_only = set(rfecv_features) - set(mi_features)\n",
    "mi_only = set(mi_features) - set(rfecv_features)\n",
    "print(f\"\\nğŸ”¹ RFECV-only features: {rfecv_only}\")\n",
    "print(f\"ğŸ”¹ MI-only features: {mi_only}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de319503",
   "metadata": {},
   "source": [
    "## ğŸ“ Conclusion & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“ KESIMPULAN & REKOMENDASI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate percentage differences\n",
    "rmse_diff = abs(rmse_rfecv - rmse_mi) / min(rmse_rfecv, rmse_mi) * 100\n",
    "r2_diff = abs(r2_rfecv - r2_mi) / max(r2_rfecv, r2_mi) * 100\n",
    "time_diff = abs((rfecv_time + train_time_rfecv) - (mi_time + train_time_mi)) / min(rfecv_time + train_time_rfecv, mi_time + train_time_mi) * 100\n",
    "\n",
    "print(f\"\\nğŸ“Š Performance Differences:\")\n",
    "print(f\"  â€¢ RMSE difference: {rmse_diff:.2f}%\")\n",
    "print(f\"  â€¢ RÂ² difference: {r2_diff:.2f}%\")\n",
    "print(f\"  â€¢ Time difference: {time_diff:.2f}%\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Recommendations:\")\n",
    "\n",
    "if rmse_rfecv < rmse_mi and r2_rfecv > r2_mi:\n",
    "    print(\"  âœ… RFECV is BETTER for prediction accuracy\")\n",
    "    print(\"  ğŸ“Œ Use RFECV when: Accuracy is critical, computational time is acceptable\")\n",
    "elif rmse_mi < rmse_rfecv and r2_mi > r2_rfecv:\n",
    "    print(\"  âœ… Mutual Information is BETTER for prediction accuracy\")\n",
    "    print(\"  ğŸ“Œ Use MI when: Need fast results with good accuracy\")\n",
    "else:\n",
    "    print(\"  âš–ï¸ Both methods perform SIMILARLY on accuracy\")\n",
    "    \n",
    "if (mi_time + train_time_mi) < (rfecv_time + train_time_rfecv):\n",
    "    speed_ratio = (rfecv_time + train_time_rfecv) / (mi_time + train_time_mi)\n",
    "    print(f\"  âš¡ MI is {speed_ratio:.1f}x FASTER than RFECV\")\n",
    "    print(\"  ğŸ“Œ Advantage: Quick iterations, real-time applications\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Best Practice:\")\n",
    "print(\"  1ï¸âƒ£ Use MI for fast initial feature selection\")\n",
    "print(\"  2ï¸âƒ£ Use RFECV for final model optimization\")\n",
    "print(\"  3ï¸âƒ£ Compare both to understand feature importance from different perspectives\")\n",
    "\n",
    "print(\"\\nâœ… Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-mining-final-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
