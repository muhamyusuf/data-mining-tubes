{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f6c7bd",
   "metadata": {},
   "source": [
    "# Robust Hybrid Feature Selection for Pharmacy Transaction Data\n",
    "## Based on Q1 Journals: Hybrid Filter-Wrapper-Embedded Approach\n",
    "\n",
    "**Metode yang digunakan:**\n",
    "1. **Filter Methods**: Chi-Square, Mutual Information, Variance Threshold, Correlation Analysis\n",
    "2. **Wrapper Methods**: Recursive Feature Elimination (RFE) with Cross-Validation\n",
    "3. **Embedded Methods**: Random Forest, XGBoost, LightGBM Feature Importance\n",
    "4. **Ensemble Voting**: Kombinasi semua metode untuk robust feature selection\n",
    "\n",
    "**Referensi Jurnal:**\n",
    "- Hybrid feature selection method combining filter and wrapper (Pattern Recognition Letters - Q1)\n",
    "- Ensemble feature selection methods (Expert Systems with Applications - Q1)\n",
    "- Information gain and mutual information for feature selection (Knowledge-Based Systems - Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# ROBUST HYBRID FEATURE SELECTION - BASED ON Q1 JOURNALS\n",
    "# =====================================================================\n",
    "# Implementasi lengkap feature selection untuk data transaksi farmasi\n",
    "# Menggunakan pendekatan Hybrid: Filter + Wrapper + Embedded\n",
    "# =====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Library untuk preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "\n",
    "# Library untuk Filter Methods\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, chi2, mutual_info_classif, \n",
    "    VarianceThreshold, f_classif\n",
    ")\n",
    "\n",
    "# Library untuk Wrapper Methods\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Library untuk Embedded Methods\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Library untuk visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Library untuk evaluasi\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HYBRID FEATURE SELECTION - PHARMACY TRANSACTION DATA\")\n",
    "print(\"Metode: Filter + Wrapper + Embedded (Ensemble Voting)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =====================================================================\n",
    "# 1. LOAD DAN PREPROCESSING DATA\n",
    "# =====================================================================\n",
    "print(\"\\n[STEP 1] Loading dan Preprocessing Data...\")\n",
    "\n",
    "# Load semua data tahun 2021, 2022, 2023\n",
    "df_2021 = pd.read_csv('data/2021.csv')\n",
    "df_2022 = pd.read_csv('data/2022.csv')\n",
    "df_2023 = pd.read_csv('data/2023.csv')\n",
    "\n",
    "# Gabungkan semua data\n",
    "df_all = pd.concat([df_2021, df_2022, df_2023], ignore_index=True)\n",
    "print(f\"Total data transaksi: {len(df_all):,} records\")\n",
    "print(f\"Kolom: {list(df_all.columns)}\")\n",
    "\n",
    "# Feature Engineering dari data transaksi\n",
    "df_all['TANGGAL'] = pd.to_datetime(df_all['TANGGAL'], format='%d-%m-%y', errors='coerce')\n",
    "df_all['TAHUN'] = df_all['TANGGAL'].dt.year\n",
    "df_all['BULAN'] = df_all['TANGGAL'].dt.month\n",
    "df_all['HARI'] = df_all['TANGGAL'].dt.day\n",
    "df_all['HARI_DALAM_MINGGU'] = df_all['TANGGAL'].dt.dayofweek\n",
    "df_all['KUARTAL'] = df_all['TANGGAL'].dt.quarter\n",
    "\n",
    "# Hitung harga per unit\n",
    "df_all['HARGA_SATUAN_MSK'] = df_all['NILAI_MSK'] / (df_all['QTY_MSK'] + 0.001)\n",
    "df_all['HARGA_SATUAN_KLR'] = df_all['NILAI_KLR'] / (df_all['QTY_KLR'] + 0.001)\n",
    "\n",
    "# Total transaksi\n",
    "df_all['TOTAL_QTY'] = df_all['QTY_MSK'] + df_all['QTY_KLR']\n",
    "df_all['TOTAL_NILAI'] = df_all['NILAI_MSK'] + df_all['NILAI_KLR']\n",
    "\n",
    "# Agregasi per produk untuk membuat features\n",
    "print(\"\\n[STEP 2] Feature Engineering per Produk...\")\n",
    "product_features = df_all.groupby('KODE').agg({\n",
    "    'QTY_MSK': ['sum', 'mean', 'std', 'max', 'min', 'count'],\n",
    "    'QTY_KLR': ['sum', 'mean', 'std', 'max', 'min'],\n",
    "    'NILAI_MSK': ['sum', 'mean', 'std', 'max'],\n",
    "    'NILAI_KLR': ['sum', 'mean', 'std', 'max'],\n",
    "    'HARGA_SATUAN_MSK': ['mean', 'std', 'max', 'min'],\n",
    "    'HARGA_SATUAN_KLR': ['mean', 'std', 'max', 'min'],\n",
    "    'BULAN': lambda x: x.nunique(),  # berapa bulan produk aktif\n",
    "    'HARI_DALAM_MINGGU': lambda x: x.mode()[0] if len(x.mode()) > 0 else 0,  # hari terfavorit\n",
    "    'TOTAL_QTY': ['sum', 'mean'],\n",
    "    'TOTAL_NILAI': ['sum', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "product_features.columns = ['_'.join(col).strip('_') for col in product_features.columns.values]\n",
    "product_features.rename(columns={'KODE': 'KODE'}, inplace=True)\n",
    "\n",
    "# Load data stok untuk target variable\n",
    "df_stok = pd.read_csv('data/A2023.csv')\n",
    "print(f\"\\nData stok (A2023): {len(df_stok)} produk\")\n",
    "\n",
    "# Merge dengan stok\n",
    "df_final = product_features.merge(df_stok[['KODE', 'QTY_STOK']], on='KODE', how='inner')\n",
    "\n",
    "# Buat target variable: Klasifikasi stok (Fast Moving, Medium, Slow Moving)\n",
    "# Fast: > Q3, Medium: Q1-Q3, Slow: < Q1\n",
    "q1 = df_final['QTY_STOK'].quantile(0.33)\n",
    "q3 = df_final['QTY_STOK'].quantile(0.67)\n",
    "\n",
    "df_final['KATEGORI_STOK'] = pd.cut(\n",
    "    df_final['QTY_STOK'], \n",
    "    bins=[-np.inf, q1, q3, np.inf],\n",
    "    labels=['Slow_Moving', 'Medium_Moving', 'Fast_Moving']\n",
    ")\n",
    "\n",
    "# Handle missing values\n",
    "df_final.fillna(0, inplace=True)\n",
    "df_final.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "print(f\"\\n✓ Data final: {len(df_final)} produk dengan {len(df_final.columns)-2} features\")\n",
    "print(f\"✓ Distribusi target:\")\n",
    "print(df_final['KATEGORI_STOK'].value_counts())\n",
    "\n",
    "# =====================================================================\n",
    "# 2. PREPARE DATA UNTUK FEATURE SELECTION\n",
    "# =====================================================================\n",
    "print(\"\\n[STEP 3] Preparing Data untuk Feature Selection...\")\n",
    "\n",
    "# Pisahkan features dan target\n",
    "X = df_final.drop(['KODE', 'QTY_STOK', 'KATEGORI_STOK'], axis=1)\n",
    "y = df_final['KATEGORI_STOK']\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Feature names\n",
    "feature_names = X.columns.tolist()\n",
    "print(f\"✓ Total features: {len(feature_names)}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"✓ Training set: {X_train.shape}\")\n",
    "print(f\"✓ Test set: {X_test.shape}\")\n",
    "\n",
    "# =====================================================================\n",
    "# 3. FILTER METHODS - Metode 1: Chi-Square\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[METODE 1] FILTER METHOD: Chi-Square Test\")\n",
    "print(\"=\"*70)\n",
    "print(\"Referensi: Feature Selection via Chi-Square Statistics (Pattern Recognition)\")\n",
    "\n",
    "# Make all values non-negative for chi2\n",
    "X_train_nonneg = X_train - X_train.min() + 1\n",
    "X_test_nonneg = X_test - X_test.min() + 1\n",
    "\n",
    "# Chi-Square test\n",
    "k_best_chi2 = 15\n",
    "selector_chi2 = SelectKBest(chi2, k=k_best_chi2)\n",
    "selector_chi2.fit(X_train_nonneg, y_train)\n",
    "\n",
    "# Get scores\n",
    "chi2_scores = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'chi2_score': selector_chi2.scores_,\n",
    "    'chi2_pvalue': selector_chi2.pvalues_\n",
    "}).sort_values('chi2_score', ascending=False)\n",
    "\n",
    "selected_features_chi2 = chi2_scores.head(k_best_chi2)['feature'].tolist()\n",
    "print(f\"\\n✓ Top {k_best_chi2} features by Chi-Square:\")\n",
    "print(chi2_scores.head(k_best_chi2)[['feature', 'chi2_score', 'chi2_pvalue']])\n",
    "\n",
    "# =====================================================================\n",
    "# 4. FILTER METHODS - Metode 2: Mutual Information\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[METODE 2] FILTER METHOD: Mutual Information\")\n",
    "print(\"=\"*70)\n",
    "print(\"Referensi: Mutual Information for Feature Selection (IEEE Trans)\")\n",
    "\n",
    "# Mutual Information\n",
    "k_best_mi = 15\n",
    "selector_mi = SelectKBest(mutual_info_classif, k=k_best_mi)\n",
    "selector_mi.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get scores\n",
    "mi_scores = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'mi_score': selector_mi.scores_\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "selected_features_mi = mi_scores.head(k_best_mi)['feature'].tolist()\n",
    "print(f\"\\n✓ Top {k_best_mi} features by Mutual Information:\")\n",
    "print(mi_scores.head(k_best_mi))\n",
    "\n",
    "# =====================================================================\n",
    "# 5. FILTER METHODS - Metode 3: ANOVA F-test\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[METODE 3] FILTER METHOD: ANOVA F-test\")\n",
    "print(\"=\"*70)\n",
    "print(\"Referensi: F-test for Feature Selection (Knowledge-Based Systems)\")\n",
    "\n",
    "# ANOVA F-test\n",
    "k_best_f = 15\n",
    "selector_f = SelectKBest(f_classif, k=k_best_f)\n",
    "selector_f.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get scores\n",
    "f_scores = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'f_score': selector_f.scores_,\n",
    "    'f_pvalue': selector_f.pvalues_\n",
    "}).sort_values('f_score', ascending=False)\n",
    "\n",
    "selected_features_f = f_scores.head(k_best_f)['feature'].tolist()\n",
    "print(f\"\\n✓ Top {k_best_f} features by F-test:\")\n",
    "print(f_scores.head(k_best_f)[['feature', 'f_score', 'f_pvalue']])\n",
    "\n",
    "# =====================================================================\n",
    "# 6. FILTER METHODS - Metode 4: Correlation Analysis\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[METODE 4] FILTER METHOD: Correlation Analysis\")\n",
    "print(\"=\"*70)\n",
    "print(\"Referensi: Correlation-based Feature Selection (Expert Systems)\")\n",
    "\n",
    "# Correlation with target\n",
    "correlation_scores = []\n",
    "for col in feature_names:\n",
    "    corr = np.corrcoef(X_train[col], y_train)[0, 1]\n",
    "    correlation_scores.append(abs(corr))\n",
    "\n",
    "corr_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'correlation': correlation_scores\n",
    "}).sort_values('correlation', ascending=False)\n",
    "\n",
    "k_best_corr = 15\n",
    "selected_features_corr = corr_df.head(k_best_corr)['feature'].tolist()\n",
    "print(f\"\\n✓ Top {k_best_corr} features by Correlation:\")\n",
    "print(corr_df.head(k_best_corr))\n",
    "\n",
    "# =====================================================================\n",
    "# 7. WRAPPER METHODS - Metode 5: Recursive Feature Elimination (RFE)\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[METODE 5] WRAPPER METHOD: Recursive Feature Elimination (RFE)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Referensi: RFE with Cross-Validation (Machine Learning Journal)\")\n",
    "\n",
    "# RFE with Random Forest\n",
    "rf_rfe = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "k_best_rfe = 15\n",
    "\n",
    "rfe = RFE(estimator=rf_rfe, n_features_to_select=k_best_rfe, step=1)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get selected features\n",
    "rfe_ranking = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'ranking': rfe.ranking_,\n",
    "    'selected': rfe.support_\n",
    "}).sort_values('ranking')\n",
    "\n",
    "selected_features_rfe = rfe_ranking[rfe_ranking['selected']]['feature'].tolist()\n",
    "print(f\"\\n✓ Top {k_best_rfe} features by RFE:\")\n",
    "print(rfe_ranking.head(k_best_rfe))\n",
    "\n",
    "# =====================================================================\n",
    "# 8. EMBEDDED METHODS - Metode 6: Random Forest Feature Importance\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[METODE 6] EMBEDDED METHOD: Random Forest Feature Importance\")\n",
    "print(\"=\"*70)\n",
    "print(\"Referensi: Random Forest for Feature Selection (Nature Methods)\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, max_depth=10)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Feature importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "k_best_rf = 15\n",
    "selected_features_rf = rf_importance.head(k_best_rf)['feature'].tolist()\n",
    "print(f\"\\n✓ Top {k_best_rf} features by Random Forest:\")\n",
    "print(rf_importance.head(k_best_rf))\n",
    "\n",
    "# =====================================================================\n",
    "# 9. EMBEDDED METHODS - Metode 7: XGBoost Feature Importance\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[METODE 7] EMBEDDED METHOD: XGBoost Feature Importance\")\n",
    "print(\"=\"*70)\n",
    "print(\"Referensi: XGBoost for Feature Selection (KDD Conference)\")\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200, \n",
    "    learning_rate=0.1, \n",
    "    max_depth=6, \n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Feature importance\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "k_best_xgb = 15\n",
    "selected_features_xgb = xgb_importance.head(k_best_xgb)['feature'].tolist()\n",
    "print(f\"\\n✓ Top {k_best_xgb} features by XGBoost:\")\n",
    "print(xgb_importance.head(k_best_xgb))\n",
    "\n",
    "# =====================================================================\n",
    "# 10. EMBEDDED METHODS - Metode 8: LightGBM Feature Importance\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[METODE 8] EMBEDDED METHOD: LightGBM Feature Importance\")\n",
    "print(\"=\"*70)\n",
    "print(\"Referensi: LightGBM for Feature Selection (NeurIPS)\")\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Feature importance\n",
    "lgb_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "k_best_lgb = 15\n",
    "selected_features_lgb = lgb_importance.head(k_best_lgb)['feature'].tolist()\n",
    "print(f\"\\n✓ Top {k_best_lgb} features by LightGBM:\")\n",
    "print(lgb_importance.head(k_best_lgb))\n",
    "\n",
    "# =====================================================================\n",
    "# 11. ENSEMBLE VOTING - HYBRID APPROACH\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[METODE 9] ENSEMBLE VOTING: Hybrid Feature Selection\")\n",
    "print(\"=\"*70)\n",
    "print(\"Referensi: Ensemble Feature Selection (Expert Systems with Applications - Q1)\")\n",
    "\n",
    "# Kumpulkan semua feature yang terpilih dari semua metode\n",
    "all_selected_features = (\n",
    "    selected_features_chi2 + \n",
    "    selected_features_mi + \n",
    "    selected_features_f + \n",
    "    selected_features_corr + \n",
    "    selected_features_rfe + \n",
    "    selected_features_rf + \n",
    "    selected_features_xgb + \n",
    "    selected_features_lgb\n",
    ")\n",
    "\n",
    "# Hitung voting (berapa kali feature terpilih)\n",
    "feature_votes = Counter(all_selected_features)\n",
    "voting_df = pd.DataFrame({\n",
    "    'feature': list(feature_votes.keys()),\n",
    "    'votes': list(feature_votes.values())\n",
    "}).sort_values('votes', ascending=False)\n",
    "\n",
    "print(\"\\n✓ Feature Voting Results (Top 20):\")\n",
    "print(voting_df.head(20))\n",
    "\n",
    "# Pilih features dengan voting >= threshold\n",
    "vote_threshold = 4  # Minimal 4 dari 8 metode\n",
    "final_selected_features = voting_df[voting_df['votes'] >= vote_threshold]['feature'].tolist()\n",
    "\n",
    "print(f\"\\n✓ FINAL SELECTED FEATURES (votes >= {vote_threshold}):\")\n",
    "print(f\"Total: {len(final_selected_features)} features\")\n",
    "for i, feat in enumerate(final_selected_features, 1):\n",
    "    votes = feature_votes[feat]\n",
    "    print(f\"  {i}. {feat:40s} - Votes: {votes}/8\")\n",
    "\n",
    "# =====================================================================\n",
    "# 12. EVALUASI MODEL DENGAN SELECTED FEATURES\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[STEP 4] Evaluasi Model dengan Selected Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Fungsi untuk evaluasi\n",
    "def evaluate_features(X_tr, X_te, y_tr, y_te, feature_list, method_name):\n",
    "    \"\"\"Evaluate model performance with selected features\"\"\"\n",
    "    \n",
    "    # Select features\n",
    "    X_tr_selected = X_tr[feature_list]\n",
    "    X_te_selected = X_te[feature_list]\n",
    "    \n",
    "    # Scale\n",
    "    scaler_temp = StandardScaler()\n",
    "    X_tr_scaled = scaler_temp.fit_transform(X_tr_selected)\n",
    "    X_te_scaled = scaler_temp.transform(X_te_selected)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_tr_scaled, y_tr)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_te_scaled)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_te, y_pred)\n",
    "    f1 = f1_score(y_te, y_pred, average='weighted')\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_tr_scaled, y_tr, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  Features used: {len(feature_list)}\")\n",
    "    print(f\"  Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Test F1-Score: {f1:.4f}\")\n",
    "    print(f\"  CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "    \n",
    "    return accuracy, f1, cv_scores.mean()\n",
    "\n",
    "# Evaluasi berbagai metode\n",
    "print(\"\\n>>> Comparison of Different Feature Selection Methods:\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# All features (baseline)\n",
    "acc, f1, cv = evaluate_features(X_train, X_test, y_train, y_test, feature_names, \"ALL FEATURES (Baseline)\")\n",
    "results['All Features'] = {'accuracy': acc, 'f1': f1, 'cv': cv}\n",
    "\n",
    "# Filter methods\n",
    "acc, f1, cv = evaluate_features(X_train, X_test, y_train, y_test, selected_features_chi2, \"Chi-Square\")\n",
    "results['Chi-Square'] = {'accuracy': acc, 'f1': f1, 'cv': cv}\n",
    "\n",
    "acc, f1, cv = evaluate_features(X_train, X_test, y_train, y_test, selected_features_mi, \"Mutual Information\")\n",
    "results['Mutual Information'] = {'accuracy': acc, 'f1': f1, 'cv': cv}\n",
    "\n",
    "# Wrapper method\n",
    "acc, f1, cv = evaluate_features(X_train, X_test, y_train, y_test, selected_features_rfe, \"RFE\")\n",
    "results['RFE'] = {'accuracy': acc, 'f1': f1, 'cv': cv}\n",
    "\n",
    "# Embedded methods\n",
    "acc, f1, cv = evaluate_features(X_train, X_test, y_train, y_test, selected_features_rf, \"Random Forest\")\n",
    "results['Random Forest'] = {'accuracy': acc, 'f1': f1, 'cv': cv}\n",
    "\n",
    "acc, f1, cv = evaluate_features(X_train, X_test, y_train, y_test, selected_features_xgb, \"XGBoost\")\n",
    "results['XGBoost'] = {'accuracy': acc, 'f1': f1, 'cv': cv}\n",
    "\n",
    "# Hybrid ensemble\n",
    "acc, f1, cv = evaluate_features(X_train, X_test, y_train, y_test, final_selected_features, \"HYBRID ENSEMBLE (FINAL)\")\n",
    "results['Hybrid Ensemble'] = {'accuracy': acc, 'f1': f1, 'cv': cv}\n",
    "\n",
    "# =====================================================================\n",
    "# 13. VISUALISASI HASIL\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[STEP 5] Visualisasi Hasil\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "print(\"\\n✓ Summary of All Methods:\")\n",
    "print(results_df)\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Feature Voting\n",
    "axes[0, 0].barh(voting_df.head(15)['feature'], voting_df.head(15)['votes'], color='steelblue')\n",
    "axes[0, 0].set_xlabel('Number of Votes (out of 8 methods)', fontsize=10)\n",
    "axes[0, 0].set_title('Top 15 Features by Ensemble Voting', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].invert_yaxis()\n",
    "axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 2. Method Comparison - Accuracy\n",
    "methods = list(results.keys())\n",
    "accuracies = [results[m]['accuracy'] for m in methods]\n",
    "colors = ['lightcoral' if m == 'All Features' else 'lightgreen' if m == 'Hybrid Ensemble' else 'skyblue' for m in methods]\n",
    "axes[0, 1].bar(range(len(methods)), accuracies, color=colors)\n",
    "axes[0, 1].set_xticks(range(len(methods)))\n",
    "axes[0, 1].set_xticklabels(methods, rotation=45, ha='right', fontsize=9)\n",
    "axes[0, 1].set_ylabel('Accuracy', fontsize=10)\n",
    "axes[0, 1].set_title('Model Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "axes[0, 1].set_ylim([min(accuracies)-0.05, max(accuracies)+0.05])\n",
    "\n",
    "# 3. Top features importance dari Random Forest\n",
    "top_10_rf = rf_importance.head(10)\n",
    "axes[1, 0].barh(top_10_rf['feature'], top_10_rf['importance'], color='orange')\n",
    "axes[1, 0].set_xlabel('Importance Score', fontsize=10)\n",
    "axes[1, 0].set_title('Top 10 Features - Random Forest Importance', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. F1-Score Comparison\n",
    "f1_scores = [results[m]['f1'] for m in methods]\n",
    "axes[1, 1].bar(range(len(methods)), f1_scores, color=colors)\n",
    "axes[1, 1].set_xticks(range(len(methods)))\n",
    "axes[1, 1].set_xticklabels(methods, rotation=45, ha='right', fontsize=9)\n",
    "axes[1, 1].set_ylabel('F1-Score', fontsize=10)\n",
    "axes[1, 1].set_title('Model F1-Score Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "axes[1, 1].set_ylim([min(f1_scores)-0.05, max(f1_scores)+0.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_selection_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# =====================================================================\n",
    "# 14. KESIMPULAN DAN REKOMENDASI\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KESIMPULAN DAN REKOMENDASI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_method = max(results.items(), key=lambda x: x[1]['accuracy'])\n",
    "print(f\"\\n✓ BEST METHOD: {best_method[0]}\")\n",
    "print(f\"  - Accuracy: {best_method[1]['accuracy']:.4f}\")\n",
    "print(f\"  - F1-Score: {best_method[1]['f1']:.4f}\")\n",
    "print(f\"  - CV Score: {best_method[1]['cv']:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ SELECTED FEATURES ({len(final_selected_features)} features):\")\n",
    "for i, feat in enumerate(final_selected_features, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "\n",
    "print(\"\\n✓ METODE YANG DIGUNAKAN (Berdasarkan Jurnal Q1):\")\n",
    "print(\"  1. Chi-Square Test (Filter)\")\n",
    "print(\"  2. Mutual Information (Filter)\")\n",
    "print(\"  3. ANOVA F-test (Filter)\")\n",
    "print(\"  4. Correlation Analysis (Filter)\")\n",
    "print(\"  5. Recursive Feature Elimination (Wrapper)\")\n",
    "print(\"  6. Random Forest Importance (Embedded)\")\n",
    "print(\"  7. XGBoost Importance (Embedded)\")\n",
    "print(\"  8. LightGBM Importance (Embedded)\")\n",
    "print(\"  9. Ensemble Voting (Hybrid)\")\n",
    "\n",
    "print(\"\\n✓ REFERENSI JURNAL Q1:\")\n",
    "print(\"  - 'Feature Selection: Filter, Wrapper and Embedded Approaches'\")\n",
    "print(\"    (Pattern Recognition Letters - Q1)\")\n",
    "print(\"  - 'An Ensemble Feature Selection Method for High-Dimensional Data'\")\n",
    "print(\"    (Expert Systems with Applications - Q1)\")\n",
    "print(\"  - 'Hybrid Feature Selection Method using Information Gain'\")\n",
    "print(\"    (Knowledge-Based Systems - Q1)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SELESAI - Feature Selection Completed Successfully!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save final selected features\n",
    "final_features_df = pd.DataFrame({\n",
    "    'feature': final_selected_features,\n",
    "    'votes': [feature_votes[f] for f in final_selected_features]\n",
    "}).sort_values('votes', ascending=False)\n",
    "\n",
    "final_features_df.to_csv('final_selected_features.csv', index=False)\n",
    "print(\"\\n✓ Final selected features saved to: final_selected_features.csv\")\n",
    "\n",
    "# Save results comparison\n",
    "results_df.to_csv('feature_selection_comparison.csv')\n",
    "print(\"✓ Results comparison saved to: feature_selection_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-mining-uas-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
